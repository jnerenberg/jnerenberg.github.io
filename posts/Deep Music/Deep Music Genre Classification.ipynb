{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Deep Music Genre Classification\"\n",
    "author: Julia Nerenberg\n",
    "type: \"Blog Post\"\n",
    "date: 2024-05-17 \n",
    "description: |\n",
    "    In this blog post, I'll use PyTorch to perform classification on a data set of song attributes, comparing approaches that use only lyrics, approaches that use only quantitative audio features, and approaches that use both. \n",
    "objectives: \n",
    "  - Theory, Experimentation\n",
    "publish: \"true\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 0451: Deep Music Genre Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "This blog post will explore classification of music genre from a variety of features using PyTorch. I will implement 3 different neural networks with Torch and train them on the dataset. The first network will use only the lyrics, the second will use only the engineered features, and the third will use both the lyrics and the engineered features. I will compare the performance of the three networks and discuss the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/PhilChodrow/PIC16B/master/datasets/tcc_ceds_music.csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>release_date</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>len</th>\n",
       "      <th>dating</th>\n",
       "      <th>violence</th>\n",
       "      <th>world/life</th>\n",
       "      <th>...</th>\n",
       "      <th>sadness</th>\n",
       "      <th>feelings</th>\n",
       "      <th>danceability</th>\n",
       "      <th>loudness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>valence</th>\n",
       "      <th>energy</th>\n",
       "      <th>topic</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>mukesh</td>\n",
       "      <td>mohabbat bhi jhoothi</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>hold time feel break feel untrue convince spea...</td>\n",
       "      <td>95</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.063746</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380299</td>\n",
       "      <td>0.117175</td>\n",
       "      <td>0.357739</td>\n",
       "      <td>0.454119</td>\n",
       "      <td>0.997992</td>\n",
       "      <td>0.901822</td>\n",
       "      <td>0.339448</td>\n",
       "      <td>0.137110</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>frankie laine</td>\n",
       "      <td>i believe</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>believe drop rain fall grow believe darkest ni...</td>\n",
       "      <td>51</td>\n",
       "      <td>0.035537</td>\n",
       "      <td>0.096777</td>\n",
       "      <td>0.443435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.331745</td>\n",
       "      <td>0.647540</td>\n",
       "      <td>0.954819</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.325021</td>\n",
       "      <td>0.263240</td>\n",
       "      <td>world/life</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>johnnie ray</td>\n",
       "      <td>cry</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>sweetheart send letter goodbye secret feel bet...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.225422</td>\n",
       "      <td>0.456298</td>\n",
       "      <td>0.585288</td>\n",
       "      <td>0.840361</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.351814</td>\n",
       "      <td>0.139112</td>\n",
       "      <td>music</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>pérez prado</td>\n",
       "      <td>patricia</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>kiss lips want stroll charm mambo chacha merin...</td>\n",
       "      <td>54</td>\n",
       "      <td>0.048249</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225889</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.686992</td>\n",
       "      <td>0.744404</td>\n",
       "      <td>0.083935</td>\n",
       "      <td>0.199393</td>\n",
       "      <td>0.775350</td>\n",
       "      <td>0.743736</td>\n",
       "      <td>romantic</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>giorgos papadopoulos</td>\n",
       "      <td>apopse eida oneiro</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>till darling till matter know till dream live ...</td>\n",
       "      <td>48</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.417772</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.291671</td>\n",
       "      <td>0.646489</td>\n",
       "      <td>0.975904</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.597073</td>\n",
       "      <td>0.394375</td>\n",
       "      <td>romantic</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           artist_name            track_name  release_date genre  \\\n",
       "0           0                mukesh  mohabbat bhi jhoothi          1950   pop   \n",
       "1           4         frankie laine             i believe          1950   pop   \n",
       "2           6           johnnie ray                   cry          1950   pop   \n",
       "3          10           pérez prado              patricia          1950   pop   \n",
       "4          12  giorgos papadopoulos    apopse eida oneiro          1950   pop   \n",
       "\n",
       "                                              lyrics  len    dating  violence  \\\n",
       "0  hold time feel break feel untrue convince spea...   95  0.000598  0.063746   \n",
       "1  believe drop rain fall grow believe darkest ni...   51  0.035537  0.096777   \n",
       "2  sweetheart send letter goodbye secret feel bet...   24  0.002770  0.002770   \n",
       "3  kiss lips want stroll charm mambo chacha merin...   54  0.048249  0.001548   \n",
       "4  till darling till matter know till dream live ...   48  0.001350  0.001350   \n",
       "\n",
       "   world/life  ...   sadness  feelings  danceability  loudness  acousticness  \\\n",
       "0    0.000598  ...  0.380299  0.117175      0.357739  0.454119      0.997992   \n",
       "1    0.443435  ...  0.001284  0.001284      0.331745  0.647540      0.954819   \n",
       "2    0.002770  ...  0.002770  0.225422      0.456298  0.585288      0.840361   \n",
       "3    0.001548  ...  0.225889  0.001548      0.686992  0.744404      0.083935   \n",
       "4    0.417772  ...  0.068800  0.001350      0.291671  0.646489      0.975904   \n",
       "\n",
       "   instrumentalness   valence    energy       topic  age  \n",
       "0          0.901822  0.339448  0.137110     sadness  1.0  \n",
       "1          0.000002  0.325021  0.263240  world/life  1.0  \n",
       "2          0.000000  0.351814  0.139112       music  1.0  \n",
       "3          0.199393  0.775350  0.743736    romantic  1.0  \n",
       "4          0.000246  0.597073  0.394375    romantic  1.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_features = ['dating', 'violence', 'world/life', 'night/time','shake the audience','family/gospel', 'romantic', 'communication','obscene', 'music', 'movement/places', 'light/visual perceptions','family/spiritual', 'like/girls', 'sadness', 'feelings', 'danceability','loudness', 'acousticness', 'instrumentalness', 'valence', 'energy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dating</th>\n",
       "      <th>violence</th>\n",
       "      <th>world/life</th>\n",
       "      <th>night/time</th>\n",
       "      <th>shake the audience</th>\n",
       "      <th>family/gospel</th>\n",
       "      <th>romantic</th>\n",
       "      <th>communication</th>\n",
       "      <th>obscene</th>\n",
       "      <th>music</th>\n",
       "      <th>...</th>\n",
       "      <th>sadness</th>\n",
       "      <th>feelings</th>\n",
       "      <th>danceability</th>\n",
       "      <th>loudness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>valence</th>\n",
       "      <th>energy</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.063746</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.048857</td>\n",
       "      <td>0.017104</td>\n",
       "      <td>0.263751</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.039288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380299</td>\n",
       "      <td>0.117175</td>\n",
       "      <td>0.357739</td>\n",
       "      <td>0.454119</td>\n",
       "      <td>0.997992</td>\n",
       "      <td>0.901822</td>\n",
       "      <td>0.339448</td>\n",
       "      <td>0.137110</td>\n",
       "      <td>hold time feel break feel untrue convince spea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.035537</td>\n",
       "      <td>0.096777</td>\n",
       "      <td>0.443435</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.027007</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.118034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.331745</td>\n",
       "      <td>0.647540</td>\n",
       "      <td>0.954819</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.325021</td>\n",
       "      <td>0.263240</td>\n",
       "      <td>believe drop rain fall grow believe darkest ni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.158564</td>\n",
       "      <td>0.250668</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.323794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.225422</td>\n",
       "      <td>0.456298</td>\n",
       "      <td>0.585288</td>\n",
       "      <td>0.840361</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.351814</td>\n",
       "      <td>0.139112</td>\n",
       "      <td>sweetheart send letter goodbye secret feel bet...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.048249</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.411536</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225889</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.686992</td>\n",
       "      <td>0.744404</td>\n",
       "      <td>0.083935</td>\n",
       "      <td>0.199393</td>\n",
       "      <td>0.775350</td>\n",
       "      <td>0.743736</td>\n",
       "      <td>kiss lips want stroll charm mambo chacha merin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.417772</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.463430</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.291671</td>\n",
       "      <td>0.646489</td>\n",
       "      <td>0.975904</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.597073</td>\n",
       "      <td>0.394375</td>\n",
       "      <td>till darling till matter know till dream live ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dating  violence  world/life  night/time  shake the audience  \\\n",
       "0  0.000598  0.063746    0.000598    0.000598            0.000598   \n",
       "1  0.035537  0.096777    0.443435    0.001284            0.001284   \n",
       "2  0.002770  0.002770    0.002770    0.002770            0.002770   \n",
       "3  0.048249  0.001548    0.001548    0.001548            0.021500   \n",
       "4  0.001350  0.001350    0.417772    0.001350            0.001350   \n",
       "\n",
       "   family/gospel  romantic  communication   obscene     music  ...   sadness  \\\n",
       "0       0.048857  0.017104       0.263751  0.000598  0.039288  ...  0.380299   \n",
       "1       0.027007  0.001284       0.001284  0.001284  0.118034  ...  0.001284   \n",
       "2       0.002770  0.158564       0.250668  0.002770  0.323794  ...  0.002770   \n",
       "3       0.001548  0.411536       0.001548  0.001548  0.001548  ...  0.225889   \n",
       "4       0.001350  0.463430       0.001350  0.001350  0.001350  ...  0.068800   \n",
       "\n",
       "   feelings  danceability  loudness  acousticness  instrumentalness   valence  \\\n",
       "0  0.117175      0.357739  0.454119      0.997992          0.901822  0.339448   \n",
       "1  0.001284      0.331745  0.647540      0.954819          0.000002  0.325021   \n",
       "2  0.225422      0.456298  0.585288      0.840361          0.000000  0.351814   \n",
       "3  0.001548      0.686992  0.744404      0.083935          0.199393  0.775350   \n",
       "4  0.001350      0.291671  0.646489      0.975904          0.000246  0.597073   \n",
       "\n",
       "     energy                                             lyrics  genre  \n",
       "0  0.137110  hold time feel break feel untrue convince spea...      0  \n",
       "1  0.263240  believe drop rain fall grow believe darkest ni...      0  \n",
       "2  0.139112  sweetheart send letter goodbye secret feel bet...      0  \n",
       "3  0.743736  kiss lips want stroll charm mambo chacha merin...      0  \n",
       "4  0.394375  till darling till matter know till dream live ...      0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform target variable, \"genre\", into a categorical variable\n",
    "genres = {'pop': 0, 'country': 1, 'blues': 2, 'jazz': 3, 'reggae': 4, 'rock': 5, 'hip hop': 6}\n",
    "df[\"genre\"] = df[\"genre\"].apply(genres.get)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "      <th>genre</th>\n",
       "      <th>dating</th>\n",
       "      <th>violence</th>\n",
       "      <th>world/life</th>\n",
       "      <th>night/time</th>\n",
       "      <th>shake the audience</th>\n",
       "      <th>family/gospel</th>\n",
       "      <th>romantic</th>\n",
       "      <th>communication</th>\n",
       "      <th>...</th>\n",
       "      <th>family/spiritual</th>\n",
       "      <th>like/girls</th>\n",
       "      <th>sadness</th>\n",
       "      <th>feelings</th>\n",
       "      <th>danceability</th>\n",
       "      <th>loudness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>valence</th>\n",
       "      <th>energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hold time feel break feel untrue convince spea...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.063746</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.048857</td>\n",
       "      <td>0.017104</td>\n",
       "      <td>0.263751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.380299</td>\n",
       "      <td>0.117175</td>\n",
       "      <td>0.357739</td>\n",
       "      <td>0.454119</td>\n",
       "      <td>0.997992</td>\n",
       "      <td>0.901822</td>\n",
       "      <td>0.339448</td>\n",
       "      <td>0.137110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>believe drop rain fall grow believe darkest ni...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.035537</td>\n",
       "      <td>0.096777</td>\n",
       "      <td>0.443435</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.027007</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051124</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.331745</td>\n",
       "      <td>0.647540</td>\n",
       "      <td>0.954819</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.325021</td>\n",
       "      <td>0.263240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sweetheart send letter goodbye secret feel bet...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.158564</td>\n",
       "      <td>0.250668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.225422</td>\n",
       "      <td>0.456298</td>\n",
       "      <td>0.585288</td>\n",
       "      <td>0.840361</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.351814</td>\n",
       "      <td>0.139112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kiss lips want stroll charm mambo chacha merin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.048249</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.411536</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.081132</td>\n",
       "      <td>0.225889</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.686992</td>\n",
       "      <td>0.744404</td>\n",
       "      <td>0.083935</td>\n",
       "      <td>0.199393</td>\n",
       "      <td>0.775350</td>\n",
       "      <td>0.743736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>till darling till matter know till dream live ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.417772</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.463430</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029755</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.291671</td>\n",
       "      <td>0.646489</td>\n",
       "      <td>0.975904</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.597073</td>\n",
       "      <td>0.394375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              lyrics  genre    dating  \\\n",
       "0  hold time feel break feel untrue convince spea...      0  0.000598   \n",
       "1  believe drop rain fall grow believe darkest ni...      0  0.035537   \n",
       "2  sweetheart send letter goodbye secret feel bet...      0  0.002770   \n",
       "3  kiss lips want stroll charm mambo chacha merin...      0  0.048249   \n",
       "4  till darling till matter know till dream live ...      0  0.001350   \n",
       "\n",
       "   violence  world/life  night/time  shake the audience  family/gospel  \\\n",
       "0  0.063746    0.000598    0.000598            0.000598       0.048857   \n",
       "1  0.096777    0.443435    0.001284            0.001284       0.027007   \n",
       "2  0.002770    0.002770    0.002770            0.002770       0.002770   \n",
       "3  0.001548    0.001548    0.001548            0.021500       0.001548   \n",
       "4  0.001350    0.417772    0.001350            0.001350       0.001350   \n",
       "\n",
       "   romantic  communication  ...  family/spiritual  like/girls   sadness  \\\n",
       "0  0.017104       0.263751  ...          0.000598    0.000598  0.380299   \n",
       "1  0.001284       0.001284  ...          0.051124    0.001284  0.001284   \n",
       "2  0.158564       0.250668  ...          0.002770    0.002770  0.002770   \n",
       "3  0.411536       0.001548  ...          0.001548    0.081132  0.225889   \n",
       "4  0.463430       0.001350  ...          0.029755    0.001350  0.068800   \n",
       "\n",
       "   feelings  danceability  loudness  acousticness  instrumentalness   valence  \\\n",
       "0  0.117175      0.357739  0.454119      0.997992          0.901822  0.339448   \n",
       "1  0.001284      0.331745  0.647540      0.954819          0.000002  0.325021   \n",
       "2  0.225422      0.456298  0.585288      0.840361          0.000000  0.351814   \n",
       "3  0.001548      0.686992  0.744404      0.083935          0.199393  0.775350   \n",
       "4  0.001350      0.291671  0.646489      0.975904          0.000246  0.597073   \n",
       "\n",
       "     energy  \n",
       "0  0.137110  \n",
       "1  0.263240  \n",
       "2  0.139112  \n",
       "3  0.743736  \n",
       "4  0.394375  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new dataframe with only the engineered features, lyrics and the target\n",
    "df2 = df[[\"lyrics\", \"genre\"] + engineered_features]\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre\n",
       "0    7042\n",
       "1    5445\n",
       "2    4604\n",
       "5    4034\n",
       "3    3845\n",
       "4    2498\n",
       "6     904\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore the \"genre\" data distribution\n",
    "df2[\"genre\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class LyricsDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        lyrics = row[\"lyrics\"]\n",
    "        genre = row[\"genre\"]\n",
    "        features = row[engineered_features]\n",
    "        return {\n",
    "            \"lyrics\": lyrics,\n",
    "            \"features\": features,\n",
    "            \"genre\": genre\n",
    "        }\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return self.df[\"genre\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df2, test_size = 0.2, random_state = 123, shuffle=True)\n",
    "\n",
    "train_df.shape, test_df.shape\n",
    "\n",
    "train_dataset = LyricsDataset(train_df)\n",
    "val_dataset = LyricsDataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lyrics': 'cause leave heartbreaker hurt cause leave heartbreaker hurt help cause lonely need somebody want somebody cause leave heartbreaker hurt cause leave heartbreaker hurt know die know cry go life go life cause leave heartbreaker hurt cause leave heartbreaker hurt flash cause leave heartbreaker hurt cause leave heartbreaker hurt gotta gonna know deep inside treat good cause leave heartbreaker hurt cause leave heartbreaker hurt',\n",
       " 'features': dating                      0.000975\n",
       " violence                    0.000975\n",
       " world/life                  0.044549\n",
       " night/time                  0.000975\n",
       " shake the audience          0.000975\n",
       " family/gospel               0.000975\n",
       " romantic                    0.000975\n",
       " communication               0.159908\n",
       " obscene                     0.071244\n",
       " music                       0.000975\n",
       " movement/places             0.000975\n",
       " light/visual perceptions    0.000975\n",
       " family/spiritual            0.000975\n",
       " like/girls                  0.000975\n",
       " sadness                     0.560065\n",
       " feelings                    0.095207\n",
       " danceability                0.836456\n",
       " loudness                    0.517652\n",
       " acousticness                 0.03263\n",
       " instrumentalness            0.000015\n",
       " valence                     0.942292\n",
       " energy                      0.402384\n",
       " Name: 21859, dtype: object,\n",
       " 'genre': 4}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the dataloader\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop function for all three models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def train_loop(model, train_loader, val_loader, loss_fn, optimizer, device, epochs=2):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for i, data in enumerate(train_loader):\n",
    "            lyrics = data[0]\n",
    "            features = data[1]\n",
    "            genre = data[2]\n",
    "            \n",
    "            lyrics = lyrics.to(device)\n",
    "            features = features.to(device)\n",
    "            genre = genre.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(lyrics, features)\n",
    "            loss = loss_fn(outputs, genre)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                print(f\"Epoch {epoch}, iter {i}, loss: {loss.item()}\")\n",
    "                \n",
    "        val_loss, val_acc = evaluate(model, val_loader, loss_fn, device)\n",
    "        print(f\"Validation loss: {val_loss}, Validation accuracy: {val_acc}\")\n",
    "\n",
    "def evaluate(model, val_loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            lyrics = data[0]\n",
    "            features = data[1]\n",
    "            genre = data[2]\n",
    "            \n",
    "            lyrics = lyrics.to(device)\n",
    "            features = features.to(device)\n",
    "            genre = genre.to(device)\n",
    "            \n",
    "            outputs = model(lyrics, features)\n",
    "            loss = loss_fn(outputs, genre)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            preds = torch.argmax(outputs, axis = 1)\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_targets.append(genre.cpu().numpy())\n",
    "            \n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "    acc = accuracy_score(all_targets, all_preds)\n",
    "    return val_loss, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: c:\\Users\\julia\\anaconda3\\envs\\ML-2000\n",
      "\n",
      "  added / updated specs:\n",
      "    - torchtext\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    torchtext-0.6.0            |             py_1          48 KB  pytorch\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:          48 KB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  torchtext          pytorch/noarch::torchtext-0.6.0-py_1 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "torchtext-0.6.0      | 48 KB     |            |   0% \n",
      "torchtext-0.6.0      | 48 KB     | ###3       |  34% \n",
      "torchtext-0.6.0      | 48 KB     | ########## | 100% \n",
      "                                                     \n",
      "\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while loading conda entry point: anaconda-cloud-auth (cannot import name 'ChannelAuthBase' from 'conda.plugins.types' (C:\\Users\\julia\\anaconda3\\Lib\\site-packages\\conda\\plugins\\types.py))\n",
      "Error while loading conda entry point: anaconda-cloud-auth (cannot import name 'ChannelAuthBase' from 'conda.plugins.types' (C:\\Users\\julia\\anaconda3\\Lib\\site-packages\\conda\\plugins\\types.py))\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.4\n",
      "  latest version: 24.5.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=24.5.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%conda install -c pytorch torchtext -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  169,     8,   121,  ...,     0,     0,     0],\n",
       "         [   11,    11,    11,  ...,     0,     0,     0],\n",
       "         [   76,    47,     2,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [ 1189,    13,    52,  ...,     0,     0,     0],\n",
       "         [   18,   796, 39065,  ...,     0,     0,     0],\n",
       "         [  146,   356,   395,  ...,     0,     0,     0]]),\n",
       " tensor([[2.0243e-03, 4.6580e-02, 7.6299e-01, 2.0243e-03, 2.0243e-03, 2.0243e-03,\n",
       "          2.0243e-03, 7.0791e-02, 2.0243e-03, 2.0243e-03, 2.0243e-03, 2.0243e-03,\n",
       "          2.0243e-03, 2.0243e-03, 5.0386e-02, 2.0243e-03, 3.6315e-01, 5.2188e-01,\n",
       "          2.7410e-01, 1.0931e-04, 1.7045e-01, 3.6835e-01],\n",
       "         [3.0903e-02, 9.9645e-02, 6.1766e-01, 7.3099e-04, 1.1184e-01, 1.0164e-01,\n",
       "          7.3099e-04, 7.3099e-04, 7.3099e-04, 7.3099e-04, 7.3099e-04, 7.3099e-04,\n",
       "          1.2789e-02, 1.6749e-02, 7.3099e-04, 7.3099e-04, 5.7002e-01, 5.1824e-01,\n",
       "          3.9458e-01, 6.5789e-03, 8.4336e-01, 5.4553e-01],\n",
       "         [7.1634e-02, 7.9745e-04, 7.9745e-04, 7.9745e-04, 7.9745e-04, 7.9745e-04,\n",
       "          3.2714e-02, 2.2053e-01, 7.9745e-04, 4.5373e-01, 7.9745e-04, 7.9745e-04,\n",
       "          7.9745e-04, 6.5577e-02, 7.9745e-04, 3.5046e-02, 5.3969e-01, 6.9992e-01,\n",
       "          1.2651e-01, 8.9980e-04, 9.0416e-01, 6.8167e-01],\n",
       "         [1.3850e-03, 3.2795e-01, 1.3850e-03, 1.2864e-01, 1.3850e-03, 1.3850e-03,\n",
       "          1.7982e-01, 1.3850e-03, 1.3850e-03, 1.3850e-03, 1.3850e-03, 1.3850e-03,\n",
       "          3.3052e-02, 3.7798e-02, 1.2864e-01, 1.4748e-01, 5.7977e-01, 8.1419e-01,\n",
       "          3.5442e-04, 8.1781e-01, 1.3129e-01, 9.8198e-01],\n",
       "         [1.3670e-01, 3.0960e-03, 3.0366e-01, 3.0960e-03, 3.0960e-03, 3.0960e-03,\n",
       "          6.2680e-02, 1.7015e-01, 3.0960e-03, 3.0960e-03, 3.0960e-03, 3.0960e-03,\n",
       "          4.9919e-02, 5.8239e-02, 3.0960e-03, 3.0960e-03, 6.5883e-01, 6.4982e-01,\n",
       "          9.7188e-02, 5.8502e-06, 9.7115e-01, 8.3083e-01],\n",
       "         [5.5402e-04, 5.5402e-04, 5.5402e-04, 5.5402e-04, 5.5402e-04, 5.5402e-04,\n",
       "          5.5402e-04, 5.5402e-04, 5.5402e-04, 3.5042e-01, 5.5402e-04, 9.9929e-02,\n",
       "          5.5402e-04, 5.5402e-04, 3.9488e-01, 5.6874e-02, 8.1263e-01, 6.8046e-01,\n",
       "          3.3936e-01, 8.9271e-02, 4.7444e-01, 8.5585e-01],\n",
       "         [1.5949e-03, 8.4713e-02, 3.2936e-01, 1.5949e-03, 1.5949e-03, 1.5949e-03,\n",
       "          1.5949e-03, 2.3981e-01, 1.1235e-01, 1.5949e-03, 1.5949e-03, 1.5949e-03,\n",
       "          1.4220e-01, 7.0842e-02, 1.5949e-03, 1.5949e-03, 6.6425e-01, 6.7797e-01,\n",
       "          2.3494e-01, 5.9413e-06, 5.8265e-01, 5.2651e-01],\n",
       "         [1.6978e-03, 1.6978e-03, 7.6580e-01, 6.5239e-02, 1.6978e-03, 1.6978e-03,\n",
       "          1.6978e-03, 1.4180e-01, 1.6978e-03, 1.6978e-03, 1.6978e-03, 1.6978e-03,\n",
       "          1.6978e-03, 1.6978e-03, 1.6978e-03, 1.6978e-03, 5.6785e-01, 6.3464e-01,\n",
       "          3.5843e-01, 4.7976e-01, 1.9209e-01, 4.2641e-01],\n",
       "         [2.0627e-01, 8.6011e-02, 1.0965e-03, 1.0965e-03, 1.0965e-03, 1.6939e-01,\n",
       "          1.0965e-03, 1.0965e-03, 4.0132e-01, 1.0069e-01, 1.0965e-03, 1.0965e-03,\n",
       "          1.0965e-03, 1.0965e-03, 1.0965e-03, 2.2066e-02, 4.3139e-01, 6.5610e-01,\n",
       "          7.4900e-01, 2.1559e-02, 3.7036e-01, 6.1761e-01],\n",
       "         [1.3495e-03, 1.3495e-03, 1.5520e-01, 1.5218e-01, 1.3495e-03, 1.3495e-03,\n",
       "          1.3495e-03, 1.3495e-03, 1.3495e-03, 3.9327e-01, 1.3495e-03, 1.3495e-03,\n",
       "          1.4070e-01, 6.7134e-02, 1.3495e-03, 1.3495e-03, 6.7075e-01, 6.4713e-01,\n",
       "          3.8554e-01, 2.3178e-03, 7.5886e-01, 5.2851e-01],\n",
       "         [3.0960e-03, 3.0960e-03, 4.6654e-01, 3.0960e-03, 3.0960e-03, 3.0960e-03,\n",
       "          3.0960e-03, 2.1134e-01, 2.7259e-01, 3.0960e-03, 3.0960e-03, 3.0960e-03,\n",
       "          3.0960e-03, 3.0960e-03, 3.0960e-03, 3.0960e-03, 3.5557e-01, 3.3656e-01,\n",
       "          8.9960e-01, 2.0040e-01, 6.1830e-02, 1.4011e-01],\n",
       "         [1.6447e-03, 1.6447e-03, 1.6447e-03, 1.6447e-03, 1.6447e-03, 1.6447e-03,\n",
       "          3.6523e-02, 2.1589e-01, 1.3670e-01, 1.6447e-03, 1.6447e-03, 1.6447e-03,\n",
       "          7.3231e-02, 1.6447e-03, 5.1463e-01, 1.6447e-03, 4.5738e-01, 8.1735e-01,\n",
       "          3.2831e-01, 1.3360e-04, 7.5577e-01, 8.6987e-01],\n",
       "         [5.8480e-03, 5.8480e-03, 4.5029e-01, 5.8480e-03, 4.5029e-01, 5.8480e-03,\n",
       "          5.8480e-03, 5.8480e-03, 5.8480e-03, 5.8480e-03, 5.8480e-03, 5.8480e-03,\n",
       "          5.8480e-03, 5.8480e-03, 5.8480e-03, 5.8480e-03, 7.8555e-01, 6.6656e-01,\n",
       "          3.3434e-01, 3.1984e-06, 9.6496e-01, 4.8547e-01],\n",
       "         [1.2531e-03, 1.2531e-03, 1.2531e-03, 1.2531e-03, 1.2531e-03, 1.2531e-03,\n",
       "          1.2531e-03, 9.8388e-02, 5.7574e-01, 6.9896e-02, 2.0160e-01, 1.2531e-03,\n",
       "          3.6832e-02, 1.2531e-03, 1.2531e-03, 1.2531e-03, 6.3717e-01, 5.8254e-01,\n",
       "          7.6807e-01, 9.5850e-01, 1.2098e-01, 4.1440e-01],\n",
       "         [1.3495e-03, 1.3495e-03, 1.3495e-03, 1.3495e-03, 1.3495e-03, 1.3495e-03,\n",
       "          4.3306e-01, 8.0566e-02, 1.3495e-03, 1.3495e-01, 1.3495e-03, 3.3119e-01,\n",
       "          1.3495e-03, 1.3495e-03, 1.3495e-03, 1.3495e-03, 3.6207e-01, 5.6639e-01,\n",
       "          8.9659e-01, 3.0162e-05, 1.6838e-01, 2.3021e-01],\n",
       "         [2.5063e-03, 7.0278e-02, 2.5063e-03, 1.8481e-01, 2.5063e-03, 2.5063e-03,\n",
       "          4.5310e-01, 2.5063e-03, 2.5063e-03, 2.5063e-03, 2.5063e-03, 2.5063e-03,\n",
       "          2.5063e-03, 2.5063e-03, 2.5063e-03, 1.4747e-01, 7.5523e-01, 5.7137e-01,\n",
       "          1.7268e-02, 1.7105e-01, 9.5981e-01, 4.4443e-01],\n",
       "         [5.2632e-03, 5.2632e-03, 5.2632e-03, 5.2632e-03, 5.2632e-03, 5.2632e-03,\n",
       "          5.2632e-03, 5.2097e-01, 5.2632e-03, 3.2832e-01, 5.2632e-03, 5.2632e-03,\n",
       "          5.2632e-03, 6.6500e-02, 5.2632e-03, 5.2632e-03, 5.5594e-01, 6.3500e-01,\n",
       "          6.3655e-01, 0.0000e+00, 8.2378e-01, 3.3231e-01],\n",
       "         [6.4851e-02, 1.3850e-03, 3.5359e-01, 1.3850e-03, 1.3850e-03, 1.3850e-03,\n",
       "          1.3850e-03, 1.2090e-01, 1.3850e-03, 1.3850e-03, 1.3850e-03, 1.6115e-01,\n",
       "          8.4942e-02, 7.1953e-02, 1.2599e-01, 1.3850e-03, 6.5667e-01, 8.0007e-01,\n",
       "          9.0260e-02, 0.0000e+00, 7.3413e-01, 6.6065e-01],\n",
       "         [8.2237e-04, 3.2847e-01, 9.5250e-02, 8.2237e-04, 8.2237e-04, 1.6511e-01,\n",
       "          8.2237e-04, 8.2237e-04, 1.2539e-01, 8.2237e-04, 8.2237e-04, 7.6585e-02,\n",
       "          8.2237e-04, 8.2237e-04, 5.4427e-02, 4.9385e-02, 4.2272e-01, 7.6130e-01,\n",
       "          1.7570e-01, 1.2551e-05, 3.9509e-01, 5.6655e-01],\n",
       "         [4.7416e-04, 4.7416e-04, 4.7416e-04, 4.7416e-04, 1.2387e-02, 4.7416e-04,\n",
       "          4.7416e-04, 4.4285e-02, 6.9030e-01, 4.7416e-04, 4.7416e-04, 4.7416e-04,\n",
       "          4.7416e-04, 1.2551e-01, 8.0213e-02, 9.5962e-03, 8.2454e-01, 6.8474e-01,\n",
       "          2.1686e-02, 0.0000e+00, 5.3421e-01, 5.5054e-01],\n",
       "         [1.0965e-03, 4.6220e-01, 1.0965e-03, 1.0965e-03, 2.7760e-01, 1.0965e-03,\n",
       "          1.0965e-03, 6.0271e-02, 1.0965e-03, 1.0965e-03, 1.0965e-03, 6.7272e-02,\n",
       "          2.3950e-02, 1.0965e-03, 5.3295e-02, 1.0965e-03, 6.4800e-01, 6.8618e-01,\n",
       "          2.1084e-01, 4.0486e-05, 6.3623e-01, 5.6055e-01],\n",
       "         [1.0320e-03, 1.0320e-03, 3.3153e-01, 1.0320e-03, 8.4097e-02, 1.0320e-03,\n",
       "          1.0320e-03, 2.0565e-01, 1.0320e-03, 1.0320e-03, 1.0320e-03, 1.0320e-03,\n",
       "          1.0320e-03, 2.4529e-02, 1.4837e-01, 1.0320e-03, 2.1802e-01, 8.2068e-01,\n",
       "          1.6155e-03, 8.2490e-02, 2.8380e-01, 7.9179e-01],\n",
       "         [1.0121e-03, 1.0121e-03, 1.0121e-03, 1.4367e-01, 1.0121e-03, 1.0121e-03,\n",
       "          1.0121e-03, 2.8248e-01, 1.0121e-03, 1.0121e-03, 1.0121e-03, 8.2920e-02,\n",
       "          1.0121e-03, 1.0121e-03, 4.0974e-01, 1.0121e-03, 6.3067e-01, 8.5775e-01,\n",
       "          4.5281e-01, 4.4130e-05, 5.3421e-01, 7.8378e-01],\n",
       "         [8.6281e-04, 3.5068e-01, 8.6281e-04, 8.6281e-04, 8.6281e-04, 8.6281e-04,\n",
       "          8.6281e-04, 8.6281e-04, 8.6281e-04, 8.6281e-04, 3.9891e-01, 1.2454e-01,\n",
       "          2.1110e-02, 8.6281e-04, 8.6281e-04, 8.6281e-04, 5.9277e-01, 7.5599e-01,\n",
       "          9.2169e-01, 4.1397e-05, 5.9089e-01, 6.3262e-01],\n",
       "         [2.9240e-03, 4.7817e-01, 2.9240e-03, 2.9240e-03, 1.1404e-01, 2.9240e-03,\n",
       "          2.9240e-03, 2.9240e-03, 2.9240e-03, 2.9240e-03, 1.9342e-01, 2.9240e-03,\n",
       "          2.9240e-03, 1.7052e-01, 2.9240e-03, 2.9240e-03, 2.3427e-01, 6.7313e-01,\n",
       "          1.7068e-06, 4.6660e-01, 9.7321e-01, 8.7888e-01],\n",
       "         [3.2895e-03, 3.2895e-03, 3.2895e-03, 3.2895e-03, 3.2895e-03, 3.2895e-03,\n",
       "          3.2895e-03, 1.7222e-01, 2.1805e-01, 3.2895e-03, 3.2895e-03, 3.2895e-03,\n",
       "          3.2895e-03, 3.2895e-03, 3.1456e-01, 3.2895e-03, 4.3572e-01, 6.3369e-01,\n",
       "          3.8153e-01, 0.0000e+00, 1.4159e-01, 3.3431e-01],\n",
       "         [1.4225e-03, 3.8030e-01, 1.4225e-03, 1.1307e-01, 1.4225e-03, 1.4225e-03,\n",
       "          1.4225e-03, 1.4225e-03, 3.1951e-02, 1.4225e-03, 1.4225e-03, 4.2298e-01,\n",
       "          3.1787e-02, 1.4225e-03, 1.4225e-03, 1.4225e-03, 7.4223e-01, 7.4387e-01,\n",
       "          2.4296e-02, 2.2470e-02, 8.0936e-01, 8.0980e-01],\n",
       "         [8.2237e-04, 2.2313e-01, 8.2237e-04, 7.9912e-02, 8.2237e-04, 8.2237e-04,\n",
       "          8.2237e-04, 7.1804e-02, 8.2237e-04, 1.8635e-02, 8.2237e-04, 6.8491e-02,\n",
       "          8.2237e-04, 8.2237e-04, 4.4888e-01, 7.9278e-02, 3.4907e-01, 8.1078e-01,\n",
       "          9.9488e-03, 1.5688e-06, 3.0647e-01, 8.7187e-01],\n",
       "         [1.1962e-03, 1.1962e-03, 1.7487e-01, 1.1962e-03, 1.1962e-03, 1.1962e-03,\n",
       "          7.4810e-02, 1.1962e-03, 1.6093e-01, 1.1962e-03, 1.1962e-03, 1.1962e-03,\n",
       "          1.1962e-03, 1.0335e-01, 3.9612e-01, 1.1962e-03, 3.2633e-01, 7.8712e-01,\n",
       "          1.4960e-01, 8.7348e-05, 2.0754e-01, 9.1591e-01],\n",
       "         [1.0320e-03, 1.0320e-03, 3.6190e-02, 1.0320e-03, 3.3906e-02, 4.6028e-02,\n",
       "          1.0320e-03, 1.0320e-03, 5.1089e-01, 1.0320e-03, 1.4620e-01, 1.0320e-03,\n",
       "          1.0320e-03, 1.0320e-03, 6.3351e-02, 1.0320e-03, 8.9927e-01, 7.1369e-01,\n",
       "          2.8011e-02, 0.0000e+00, 8.5573e-01, 7.8278e-01],\n",
       "         [2.5063e-03, 2.5063e-03, 2.5063e-03, 2.5063e-03, 2.5063e-03, 2.5063e-03,\n",
       "          2.5063e-03, 2.5063e-03, 2.5063e-03, 4.4644e-01, 1.7748e-01, 2.5063e-03,\n",
       "          2.5063e-03, 9.1005e-02, 2.5063e-03, 2.5063e-03, 7.9530e-01, 7.4187e-01,\n",
       "          2.8815e-01, 0.0000e+00, 8.6810e-01, 8.7287e-01],\n",
       "         [6.1920e-04, 6.1920e-04, 3.8628e-01, 5.0067e-02, 3.4684e-02, 1.3261e-02,\n",
       "          6.1920e-04, 6.1920e-04, 6.1920e-04, 1.3000e-01, 1.1113e-01, 7.8759e-02,\n",
       "          6.8318e-02, 6.1920e-04, 6.1920e-04, 2.7980e-02, 3.8482e-01, 5.7539e-01,\n",
       "          1.7470e-01, 1.5385e-04, 8.3409e-01, 7.2372e-01]]),\n",
       " tensor([5, 4, 0, 5, 0, 3, 1, 3, 3, 4, 0, 1, 4, 3, 5, 0, 2, 4, 1, 6, 5, 2, 4, 2,\n",
       "         5, 1, 2, 5, 1, 6, 5, 1]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenization\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import Vocab\n",
    "from collections import Counter\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "counter = Counter()\n",
    "for line in train_df[\"lyrics\"]:\n",
    "    counter.update(tokenizer(line))\n",
    "vocab = Vocab(counter, specials=(\"<unk>\", \"<pad>\"))\n",
    "\n",
    "# collate function\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_batch(batch):\n",
    "    lyrics = [torch.tensor([vocab[token] for token in tokenizer(item[\"lyrics\"])]) for item in batch]\n",
    "    lyrics = pad_sequence(lyrics, batch_first=True)\n",
    "    features = torch.stack([torch.tensor(item[\"features\"].values.astype('float32')) for item in batch])\n",
    "    genre = torch.tensor([item[\"genre\"] for item in batch])\n",
    "    return lyrics, features, genre\n",
    "\n",
    "# data\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_batch)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_batch)\n",
    "\n",
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network 1: genre classification using only the lyrics\n",
    "from torch import nn\n",
    "\n",
    "class LyricsModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
    "        super(LyricsModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers = n_layers, \n",
    "                           bidirectional = bidirectional, \n",
    "                           dropout = dropout,\n",
    "                           batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, lyrics, features):\n",
    "        embedded = self.embedding(lyrics)\n",
    "        output, (hidden, cell) = self.rnn(embedded)\n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        return self.fc(hidden)\n",
    "    \n",
    "# hyperparameters\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 4\n",
    "hidden_dim = 32\n",
    "output_dim = 7\n",
    "n_layers = 2\n",
    "bidirectional = True\n",
    "dropout = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, iter 0, loss: 1.9052387475967407\n",
      "Epoch 0, iter 100, loss: 1.8855047225952148\n",
      "Epoch 0, iter 200, loss: 1.9408767223358154\n",
      "Epoch 0, iter 300, loss: 1.7533650398254395\n",
      "Epoch 0, iter 400, loss: 1.784616470336914\n",
      "Epoch 0, iter 500, loss: 1.7031092643737793\n",
      "Epoch 0, iter 600, loss: 1.9928700923919678\n",
      "Epoch 0, iter 700, loss: 1.7837918996810913\n",
      "Validation loss: 326.86677515506744, Validation accuracy: 0.2562114537444934\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LyricsModel(vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "train_loop(model, train_loader, val_loader, loss_fn, optimizer, device, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huh. Thats a pretty bad accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network 2: genre classification using only the engineered features\n",
    "class FeaturesModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout):\n",
    "        super(FeaturesModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, lyrics, features):\n",
    "        x = self.dropout(torch.relu(self.fc1(features)))\n",
    "        return self.fc2(x)\n",
    "    \n",
    "# hyperparameters\n",
    "input_dim = len(engineered_features)\n",
    "hidden_dim = 32\n",
    "output_dim = 7\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, iter 0, loss: 1.9866634607315063\n",
      "Epoch 0, iter 100, loss: 1.8374310731887817\n",
      "Epoch 0, iter 200, loss: 1.691967248916626\n",
      "Epoch 0, iter 300, loss: 1.899735689163208\n",
      "Epoch 0, iter 400, loss: 1.7824122905731201\n",
      "Epoch 0, iter 500, loss: 2.0268425941467285\n",
      "Epoch 0, iter 600, loss: 1.9030365943908691\n",
      "Epoch 0, iter 700, loss: 1.843409538269043\n",
      "Validation loss: 320.2576390504837, Validation accuracy: 0.2659030837004405\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "model = FeaturesModel(input_dim, hidden_dim, output_dim, dropout).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "train_loop(model, train_loader, val_loader, loss_fn, optimizer, device, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well I suppose an accuracy of 26% is better than 25%, so we have an improvement of 1% there. I think I am limited by the capabilities of my poor tablet..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network 3: genre classification using both the lyrics and the engineered features\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, input_dim):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers = n_layers, \n",
    "                           bidirectional = bidirectional, \n",
    "                           dropout = dropout,\n",
    "                           batch_first = True)\n",
    "        self.fc1 = nn.Linear(hidden_dim*2 + input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, lyrics, features):\n",
    "        embedded = self.embedding(lyrics)\n",
    "        output, (hidden, cell) = self.rnn(embedded)\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
    "        combined = torch.cat((hidden, features), dim = 1)\n",
    "        x = self.dropout(torch.relu(self.fc1(combined)))\n",
    "        return self.fc2(x)\n",
    "    \n",
    "# hyperparameters\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 4\n",
    "hidden_dim = 32\n",
    "output_dim = 7\n",
    "n_layers = 2\n",
    "bidirectional = True\n",
    "dropout = 0.5\n",
    "input_dim = len(engineered_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, iter 0, loss: 1.914614200592041\n",
      "Epoch 0, iter 100, loss: 2.0118398666381836\n",
      "Epoch 0, iter 200, loss: 1.968980312347412\n",
      "Epoch 0, iter 300, loss: 1.862599492073059\n",
      "Epoch 0, iter 400, loss: 1.8309868574142456\n",
      "Epoch 0, iter 500, loss: 1.8668416738510132\n",
      "Epoch 0, iter 600, loss: 2.001359462738037\n",
      "Epoch 0, iter 700, loss: 2.0670621395111084\n",
      "Validation loss: 327.63753485679626, Validation accuracy: 0.2562114537444934\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "model = CombinedModel(vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, input_dim).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "train_loop(model, train_loader, val_loader, loss_fn, optimizer, device, epochs=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the combined model has gone back down to 25% which is a bit disappointing. However, I am impressed that despite the low hyperparameter tuning, the model was actually able to run at all.\n",
    "\n",
    "I think that the reason this model is not performing as well is because there is soooo much loss present in the model. I think that if I were actually able to use real hyperparameter tuning, I could get a much better result from the third than the first two models individually.\n",
    "\n",
    "I cannot be too disappointed with the results, as they are slightly above the base rate of selecting 'pop' for every song, which has the highest frequency of 24%. I think that with more time and resources, I could improve the model to have a higher accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "This was a fun foray in the world of music genres. It was similar to see the different approach from how I looked at classifying song lyrics by gender in my Natural Language Processing class. I was able to get mid to high 90s accuracy using BERT and Naive Bayes models on ADA, but I think that the difference in accuracy is due to the difference in the available resources. ADA is really cool, and I would have loved to use it for this, but I am not sure how to use it with jupyter notebooks. Some of the interesting things I noticed in both projects are that the hyperparameters are everything. They can wildly change the accuracy and speed with just the smallest tuning. With my NLP final project, we were only able to avoid running out of working memory with a learning rate of 0.0001 - and thats even on ADA! I am reminded of Professor Biester's WiDS talk where she analyzed all of reddit. I have no idea what kind of computing power was necessary for that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-0451",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "debe06cc0f9553f110b64dc3926c05df82dae2145b852c8422b9c04315589dcb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
