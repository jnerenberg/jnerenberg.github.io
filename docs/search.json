[
  {
    "objectID": "posts/women in data science conference/Women-in-Data-Science.html",
    "href": "posts/women in data science conference/Women-in-Data-Science.html",
    "title": "Women in Data Science Conference",
    "section": "",
    "text": "CSCI 0451: Women in Data Science Conference\n\nAbstract\nThis blog post is a summary of and reflection of the Women in Data Science Conference that I attended on March 4, 2024. The conference was held at Middlebury College and was organized by Breanna Guo, a senior. The conference featured several speakers, including keynote speaker Sarah Brown, a Computer Science professor at the University of Rhode Island. There were many familiar faces at the conference, including several of my classmates and professors. It was a great opportunity to learn more about the field of data science and to connect with my professors and peers.\n\n\nWhy Spotlight Women in Data Science?\nUnderrepresentation of women in computing, math, and engineering contributes to a significant loss of talent and innovation in these fields. The lack of diversity in these fields is a problem because it limits the perspectives and ideas to those centered around the male demographic. This is a problem for everyone, as it means that the products and services that are created are not as inclusive or as innovative as they could be.\nThe representation and status of women in computing today differs from the 1950s and 1960s in that it has gone from a role that was predominantly filled by women to one that is predominantly filled by men. Initially, computing positions were seen as low-status, low-paying jobs that were considered to be “women’s work.” In a way, it was seen as similar to secretary work. However, as the field of computing grew and became more visible, men began to be favored for these positions as they were often seen as more competent and capable. The advent of the personal computer also played a role in this shift, as it was marketed towards gamers and the “anti-social nerd” male stereotype. This led to men being more likely to pursue careers in computing, having been encouraged by this stereotype and exposed to computers at a young age.\nMany of the barriers and unequal challenges attributed to the underrepresentation of women in computing can be eroded by events that spotlight the achievement of women in STEM. One of the main barriers is the lack of female role models and mentors in these fields. The achievements of the modern women in computer can serve to inspire and motivate young women to pursue careers in computing. Additionally, the stereotypes barring women from these fields can be broken down by showcasing their accomplishments. It is a compounding success, as the more women are spotlighted in these fields, the more likely it is that women will be encouraged to pursue careers in computing, and the more likely it is that the stereotypes will be broken down.\n\n\nThe Conference\nThe first lightning talk of the conference was Professor Amy Yuen, a Political Science professor at Middlebury College. Professor Yuen spoke about the importance of data science in the field of political science. She explained her work in using data science to analyze the United Nation’s Security Council membership changes over time. With only 15 members on the UN Security Council and 5 of which being permanent members, sponsorship plays a significant role in the election of non-permanent members. Professor Yuen argued that while this method may seem un-representative, the seats that are campaigned for general have somewhat equitable representation. This application of data science in the political sector is integral to understanding the motives of the UN and the power dynamics shaping our world.\nThe next talk was by the keynote speaker, Professor Sarah Brown, a Computer Science professor at the University of Rhode Island. Professor Brown spoke about her experiences in the field of data science as a multi-disciplinary field. She argued that data science is not just about the data, but about the people who are using the data. She emphasized the importance of collaboration between data scientists and domain experts, as well as the importance of communication skills in data science. Professor Brown also discussed diversity in the field, as it leads to more innovative and inclusive solutions. I learned that data science is not just about the data, but about the people who are using the data. I also learned that collaboration and communication are key skills in data science, and that diversity is important for creating innovative and inclusive solutions.\nProfessor Brown’s presentation was organized around three keys: contextualize data, disciplines are communities, and meet people where they are. She explained how data is a primary source of information and needs to be examined with a critical eye, much like how one would in a social studies environment. She also expressed the importance of seeking the expertise of individuals rooted within the field of study, as they can provide valuable insights that data alone cannot. Lastly, she emphasized the importance of meeting people where they are. She discussed her experiences on the board of the National Society for Black Engineers and how she realized the barriers between policy change at the higher levels and policy enaction at the lower levels. These keys, while each seeming to be a small piece of the puzzle, form a strong basis for fair and effective data science practices.\nProfessor Brown’s talk was followed by a lightning talk by Professor Jessica L’Roe, a professor of geography at Middlebury college. Her talk was focused on her experiences in using data science to analyze the usage of farmland around the world. She focused on the impact of shifts in farmland usage on local communities. She found that shifts in farmland ownership from indigenous communities to large corporations cause many families to encourage their youth to leave the farming industry. Another interesting find by Professor L’Roe concerned the reporting of farmland area owned by entities. She found that there was a much larger concentration of farms approaching the upper limits of regulations than the lower limits. While this could be a result of purchasing land in specific increments, it most likely suggests that there is a significant amount of underreporting of farmland ownership by those who own more land. Professor L’Roe’s work was a great example of how data science can be used to analyze and understand complex socio-economic and environmental issues.\nThe final talk of the conference was by Professor Laura Biester, a professor of computer science at Middlebury College. Professor Biester spoke primarily about her work in the natural language processing field, and shared some of her research on emotion detection in text posts. Amazingly, she was able to compile a dataset of almost every reddit post. Using this data, she was able to work on detection and prediction of depression in text posts. In order to ethically do this, Professor Biester relied on self reported diagnoses of depression within the dataset. Interestingly, despite the fact that these self reported diagnoses could be fabricated, those reports are few and far between, and had no significant impact on the study. Professor Biester’s work concluded by being able to somewhat accurately predict depression diagnoses from textual features in written works. In the future, this sort of work can be used to help identify individuals who may be at risk for developing depression and provide them with early intervention.\n\n\nReflection\nI was inspired by the WiDS conference. It reminded me of my reasons for choosing Computer Science as a major: it is applicable to any field. Often, computer science is seen as a field that is separate from other fields, but the WiDS conference demonstrated its unique ability to bridge the gaps between disciplines. I have always considered myself to be a multi-disciplinary person, and value adding skillsets to my toolbox. Data and computer science are the tools that facilitate this goal. In particular, it was enlightening to see the work of Professor Biester outside of the classroom. As a student of hers, I was struck by the realization that her work could one day directly benefit someone like me. It was a reminder that the work we do in the classroom is not just for the sake of learning, but for the sake of making a difference in the world. I was also stunned by how close we as students of computer science are to being able to do some of this same work. The tools and techniques that we are learning in our classes are the same ones that are being used by professionals in the field; a great reminder that we are not just students, but future professionals."
  },
  {
    "objectID": "posts/new-test-post/index.html",
    "href": "posts/new-test-post/index.html",
    "title": "Second Post",
    "section": "",
    "text": "from source import Perceptron\np = Perceptron()\n\nI did it!!\nnot implemented\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/new-test-post/index.html#math",
    "href": "posts/new-test-post/index.html#math",
    "title": "Second Post",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/goal-setting-lol/goal-setting.html",
    "href": "posts/goal-setting-lol/goal-setting.html",
    "title": "Reflective Goal-Setting",
    "section": "",
    "text": "Julia Nerenberg\n\n\nThe knowledge we’ll develop in CSCI 0451 can be broadly divided into four main areas:\n\nTheory: mathematical descriptions of frameworks and algorithms.\nImplementation: effective coding and use of tools in order to implement efficient machine learning algorithms.\nExperimentation: performing experiments to assess the performance of algorithms and clearly communicating about the results.\nSocial responsibility: critical analysis of sources of bias and harm in machine learning algorithms; theoretical formulations of fairness and bias\n\nEvery student should grow toward each of these areas, but you can choose to specialize if you’d like! If there are one or two of these categories on which you’d especially like to focus, list them below. Feel free to include any details that you’d like – this can help me tailor the course content to your interests.\nI am most interested in the Implementation and Theory aspects of Machine Learning. I already took a course at UMass Boston called “Ethics in Computing,” so I feel like I have the Social Responsibility section somewhat covered already.\n\n\n\n\n\nMost blog posts will require around 5-8 hours on average to complete, plus time for revisions in response to feedback. Blog posts will most frequently involve a mix of mathematical problem-solving, coding, experimentation, and written discussion. Some blog posts will ask you to critically discuss recent readings in an essay-like format.\nI want to complete at least 5 blog posts. I want to make sure that I am able to write about the topics that I am most interested in, so I will focus on completing those well before stressing about completing the rest. I haven’t had many classes that have required me to critically discuss recent readings, so I am excited to have an opportunity to argue, which can be a lot of fun.\n\n\n\nYou make a choice each day about how to show up for class: whether you’ll be prepared, whether you’ll engage with me and your peers in a constructive manner; and whether you’ll be active during lecture and discussions. We will also have a special opportunity this semester to engage with a renowned expert in machine learning, algorithmic bias, and the ethics of artificial intelligence.\nAn especially important form of course presence is the daily warmup. We’ll spend the first 10-15 minutes of most class periods on warmup activities. You’re expected to have prepared the warmup activity ahead of time (this means you’ll need to have completed the readings as well). Each time, we’ll sort into groups of 5-6 students, and one of you (randomly selected) will be responsible for presenting the activity on the whiteboard. If you’re not feeling prepared to present the activity, you can “pass” to the next person, or ask for help along the way.\nI want to show up to every class, baring any unexpected emergencies. I also want to show up with a strong attempt at the warm up activity. Sometimes, I’ll be somewhat absent from discussions if I don’t feel that I’ve adequately prepared, even if I have points to add. To combat this, I will always have at least some points prepared to bring up, so I don’t feel useless. For instance, today, I had a hard time thinking of a point to bring up, but I wrote down something I didn’t feel super confident about, and my group leader ended up mentioning it to the class. I also want to focus on this because having different perspectives is important, and I shouldn’t dismiss my ideas even if I dont initially feel they fit the mold given by the prompt.\n\n\n\nTo finish off the course, you’ll complete a long-term project that showcases your interests and skills. You’ll be free to propose and pursue a topic. My expectation is that most projects will move significantly beyond the content covered in class in some way: you might implement a new algorithm, study a complex data set in depth, or conduct a series of experiments related to assessing algorithmic bias in a certain class of algorithm. You’ll be expected to complete this project in small groups (of your choosing), and update us at a few milestones along the way.\nPlease share a bit about what kind of topic might excite you, and set a few goals about how you plan to show up as a constructive team-member and co-inquirer (see the ideas for some inspiration).\nI want to do a project on something I wouldn’t pick for myself. For instance, in my J-term class, I randomly chose the topic of my final project and ended up having a blast with it! I feel it will allow me to develop new opinions rather than just going into a topic that I already feel I know about. As a result, I would be happy with literally any topic. In terms of the group, Zoe would like to complete a cancer project, and I think she would like to do this on her own, but I have designated myself as her “back-up” group member if you won’t let her, so if you could get an answer to her on that so I can plan one way or another that would be wonderful. If I have to choose a topic, I would be intersted in an algorithm that identifies the most relevant personal information for sale for a given prompt. For instance, if I am stalking an individual and want to know their place of employment, I would want to purchase information regarding their location during work hours and maybe work associated emails. It would also be cool to have something that would pick up information in an image that can indicate where it was taken, like street signs, store signs, license plates’ state of origin, maybe even location of sun with respect to time and timezones. I am not a stalker. I just think it’d be neat."
  },
  {
    "objectID": "posts/goal-setting-lol/goal-setting.html#what-youll-learn",
    "href": "posts/goal-setting-lol/goal-setting.html#what-youll-learn",
    "title": "Reflective Goal-Setting",
    "section": "",
    "text": "The knowledge we’ll develop in CSCI 0451 can be broadly divided into four main areas:\n\nTheory: mathematical descriptions of frameworks and algorithms.\nImplementation: effective coding and use of tools in order to implement efficient machine learning algorithms.\nExperimentation: performing experiments to assess the performance of algorithms and clearly communicating about the results.\nSocial responsibility: critical analysis of sources of bias and harm in machine learning algorithms; theoretical formulations of fairness and bias\n\nEvery student should grow toward each of these areas, but you can choose to specialize if you’d like! If there are one or two of these categories on which you’d especially like to focus, list them below. Feel free to include any details that you’d like – this can help me tailor the course content to your interests.\nI am most interested in the Implementation and Theory aspects of Machine Learning. I already took a course at UMass Boston called “Ethics in Computing,” so I feel like I have the Social Responsibility section somewhat covered already."
  },
  {
    "objectID": "posts/goal-setting-lol/goal-setting.html#what-youll-achieve",
    "href": "posts/goal-setting-lol/goal-setting.html#what-youll-achieve",
    "title": "Reflective Goal-Setting",
    "section": "",
    "text": "Most blog posts will require around 5-8 hours on average to complete, plus time for revisions in response to feedback. Blog posts will most frequently involve a mix of mathematical problem-solving, coding, experimentation, and written discussion. Some blog posts will ask you to critically discuss recent readings in an essay-like format.\nI want to complete at least 5 blog posts. I want to make sure that I am able to write about the topics that I am most interested in, so I will focus on completing those well before stressing about completing the rest. I haven’t had many classes that have required me to critically discuss recent readings, so I am excited to have an opportunity to argue, which can be a lot of fun.\n\n\n\nYou make a choice each day about how to show up for class: whether you’ll be prepared, whether you’ll engage with me and your peers in a constructive manner; and whether you’ll be active during lecture and discussions. We will also have a special opportunity this semester to engage with a renowned expert in machine learning, algorithmic bias, and the ethics of artificial intelligence.\nAn especially important form of course presence is the daily warmup. We’ll spend the first 10-15 minutes of most class periods on warmup activities. You’re expected to have prepared the warmup activity ahead of time (this means you’ll need to have completed the readings as well). Each time, we’ll sort into groups of 5-6 students, and one of you (randomly selected) will be responsible for presenting the activity on the whiteboard. If you’re not feeling prepared to present the activity, you can “pass” to the next person, or ask for help along the way.\nI want to show up to every class, baring any unexpected emergencies. I also want to show up with a strong attempt at the warm up activity. Sometimes, I’ll be somewhat absent from discussions if I don’t feel that I’ve adequately prepared, even if I have points to add. To combat this, I will always have at least some points prepared to bring up, so I don’t feel useless. For instance, today, I had a hard time thinking of a point to bring up, but I wrote down something I didn’t feel super confident about, and my group leader ended up mentioning it to the class. I also want to focus on this because having different perspectives is important, and I shouldn’t dismiss my ideas even if I dont initially feel they fit the mold given by the prompt.\n\n\n\nTo finish off the course, you’ll complete a long-term project that showcases your interests and skills. You’ll be free to propose and pursue a topic. My expectation is that most projects will move significantly beyond the content covered in class in some way: you might implement a new algorithm, study a complex data set in depth, or conduct a series of experiments related to assessing algorithmic bias in a certain class of algorithm. You’ll be expected to complete this project in small groups (of your choosing), and update us at a few milestones along the way.\nPlease share a bit about what kind of topic might excite you, and set a few goals about how you plan to show up as a constructive team-member and co-inquirer (see the ideas for some inspiration).\nI want to do a project on something I wouldn’t pick for myself. For instance, in my J-term class, I randomly chose the topic of my final project and ended up having a blast with it! I feel it will allow me to develop new opinions rather than just going into a topic that I already feel I know about. As a result, I would be happy with literally any topic. In terms of the group, Zoe would like to complete a cancer project, and I think she would like to do this on her own, but I have designated myself as her “back-up” group member if you won’t let her, so if you could get an answer to her on that so I can plan one way or another that would be wonderful. If I have to choose a topic, I would be intersted in an algorithm that identifies the most relevant personal information for sale for a given prompt. For instance, if I am stalking an individual and want to know their place of employment, I would want to purchase information regarding their location during work hours and maybe work associated emails. It would also be cool to have something that would pick up information in an image that can indicate where it was taken, like street signs, store signs, license plates’ state of origin, maybe even location of sun with respect to time and timezones. I am not a stalker. I just think it’d be neat."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Awesome CSCI 0451 Blog",
    "section": "",
    "text": "Implementing Logistic Regression\n\n\n\n\n\nIn this blog post, you’ll implement a generalized form of gradient descent for logistic regression. \n\n\n\n\n\nMay 5, 2024\n\n\nJulia Nerenberg\n\n\n\n\n\n\n\n\n\n\n\n\nPalmer Penguins\n\n\n\n\n\nIn this blog post, I’ll work through a complete example of the standard machine learning workflow. Your primary goal is to determine the smallest number of measurements necessary to confidently determine the species of a penguin. \n\n\n\n\n\nApr 25, 2024\n\n\nJulia Nerenberg\n\n\n\n\n\n\n\n\n\n\n\n\nWomen in Data Science Conference\n\n\n\n\n\nThis blog post involves attending, reporting on, and reflecting on the Women in Data Science (WiDS) Conference at Middlebury College on March 4th, 2024. \n\n\n\n\n\nMar 4, 2024\n\n\nJulia Nerenberg\n\n\n\n\n\n\n\n\n\n\n\n\nReflective Goal-Setting\n\n\n\n\n\nWe plan our goals for learning, engagement, and achievement over the course of the semester! \n\n\n\n\n\nFeb 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nSecond Post\n\n\n\n\n\nA new blog post that I just made!\n\n\n\n\n\nMar 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\n\n\n\n\n\n\nHello Blog\n\n\n\n\n\nAn example blog post illustrating the key techniques you’ll need to demonstrate your learning in CSCI 0451.\n\n\n\n\n\nJan 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog + some extra text yay"
  },
  {
    "objectID": "posts/example-blog-post/index.html",
    "href": "posts/example-blog-post/index.html",
    "title": "Hello Blog",
    "section": "",
    "text": "from source import Perceptron\np = Perceptron()\n\nI did it!!\nnot implemented\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/example-blog-post/index.html#math",
    "href": "posts/example-blog-post/index.html#math",
    "title": "Hello Blog",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/logistic regression/Implementing Logistic Regression.html",
    "href": "posts/logistic regression/Implementing Logistic Regression.html",
    "title": "Implementing Logistic Regression",
    "section": "",
    "text": "CSCI 0451: Classifying Palmer Penguins\n\nAbstract\nThis post is an exploration of the Palmer Penguins dataset. The dataset contains measurements of penguins from three different species. I will use the dataset to train a machine learning model to classify the species of penguins based on certain measurements. I will primarily be utilizing the pandas library, but I will also make use of the scikit-learn library to train a support vector machine (SVM) model on the dataset and the matplotlib library to visualize the data and the decision boundaries of the model.\n\nimport pandas as pd\n\ntrain_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv\"\ntrain = pd.read_csv(train_url)\ntrain.head()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0809\n31\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN63A1\nYes\n11/24/08\n40.9\n16.6\n187.0\n3200.0\nFEMALE\n9.08458\n-24.54903\nNaN\n\n\n1\nPAL0809\n41\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN74A1\nYes\n11/24/08\n49.0\n19.5\n210.0\n3950.0\nMALE\n9.53262\n-24.66867\nNaN\n\n\n2\nPAL0708\n4\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN32A2\nYes\n11/27/07\n50.0\n15.2\n218.0\n5700.0\nMALE\n8.25540\n-25.40075\nNaN\n\n\n3\nPAL0708\n15\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN38A1\nYes\n12/3/07\n45.8\n14.6\n210.0\n4200.0\nFEMALE\n7.79958\n-25.62618\nNaN\n\n\n4\nPAL0809\n34\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN65A2\nYes\n11/24/08\n51.0\n18.8\n203.0\n4100.0\nMALE\n9.23196\n-24.17282\nNaN\n\n\n\n\n\n\n\nTime to clean the data.\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(train[\"Species\"])\n\ndef prepare_data(df):\n  df = df.drop([\"studyName\", \"Sample Number\", \"Individual ID\", \"Date Egg\", \"Comments\"], axis = 1)\n  df = df[df[\"Sex\"] != \".\"]\n  df = df.dropna()\n  y = le.transform(df[\"Species\"])\n  df = df.drop([\"Species\"], axis = 1)\n  df = pd.get_dummies(df)\n  return df, y\n\nX_train, y_train = prepare_data(train)\n\n\n\n\nData Exploration\nHere are some exploratory visualizations of the data.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Visualization 1\n# Pairplot of the data, colored by species\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nsns.pairplot(train, hue = \"Species\")\nplt.show()\n\n\n\n\n\n\n\n\nThis gives us a great overview of the data at a glance, but let’s take a closer look at some of the features that appear to be the most divisive between species. Seeing as the flipper length does a good job of separating the Gentoo penguins from the other two species, let’s select that at one of our initial features. We also want to look at a metric seems to isolate the two other species. Using the charts on the diagonal, we can see that delta 13 C is good for separating the Chinstraps, and the culmen length is good for separating the Adelies.\n\n# Visualization 2\n# Let's look more at the flipper length, delta 13 c, and culmen length\n# flipper length by species\nsns.boxplot(data = train, x = \"Species\", y = \"Flipper Length (mm)\")\nplt.xticks(rotation = 45)\nplt.title(\"Flipper Length by Species\")\nplt.show()\n# delta 13 c by species\nsns.boxplot(data = train, x = \"Species\", y = \"Delta 13 C (o/oo)\")\nplt.xticks(rotation = 45)\nplt.title(\"Delta 13 C by Species\")\nplt.show()\n# culmen length by species\nsns.boxplot(data = train, x = \"Species\", y = \"Culmen Length (mm)\")\nplt.xticks(rotation = 45)\nplt.title(\"Culmen Length by Species\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNow, its time for some tables. We can use the groupby function to get the mean and median values of the flipper length, delta 13 C, and culmen length for each species. This will give us a good idea of the average values for each species, and will help us to see how the species differ in terms of these features.\n\n# Mean values\nmeans = train.groupby(\"Species\")[[\"Flipper Length (mm)\", \"Delta 13 C (o/oo)\", \"Culmen Length (mm)\"]].mean()\nprint(\"Mean values\")\nprint(means)\n\nMean values\n                                           Flipper Length (mm)  \\\nSpecies                                                          \nAdelie Penguin (Pygoscelis adeliae)                 190.084034   \nChinstrap penguin (Pygoscelis antarctica)           196.000000   \nGentoo penguin (Pygoscelis papua)                   216.752577   \n\n                                           Delta 13 C (o/oo)  \\\nSpecies                                                        \nAdelie Penguin (Pygoscelis adeliae)               -25.796897   \nChinstrap penguin (Pygoscelis antarctica)         -24.553401   \nGentoo penguin (Pygoscelis papua)                 -26.149389   \n\n                                           Culmen Length (mm)  \nSpecies                                                        \nAdelie Penguin (Pygoscelis adeliae)                 38.970588  \nChinstrap penguin (Pygoscelis antarctica)           48.826316  \nGentoo penguin (Pygoscelis papua)                   47.073196  \n\n\n\n# Median values\nmedians = train.groupby(\"Species\")[[\"Flipper Length (mm)\", \"Delta 13 C (o/oo)\", \"Culmen Length (mm)\"]].median()\nprint(\"Median values\")\nprint(medians)\n\nMedian values\n                                           Flipper Length (mm)  \\\nSpecies                                                          \nAdelie Penguin (Pygoscelis adeliae)                      190.0   \nChinstrap penguin (Pygoscelis antarctica)                196.0   \nGentoo penguin (Pygoscelis papua)                        216.0   \n\n                                           Delta 13 C (o/oo)  \\\nSpecies                                                        \nAdelie Penguin (Pygoscelis adeliae)                -25.89709   \nChinstrap penguin (Pygoscelis antarctica)          -24.59467   \nGentoo penguin (Pygoscelis papua)                  -26.20455   \n\n                                           Culmen Length (mm)  \nSpecies                                                        \nAdelie Penguin (Pygoscelis adeliae)                      38.9  \nChinstrap penguin (Pygoscelis antarctica)                49.3  \nGentoo penguin (Pygoscelis papua)                        46.5  \n\n\nWhile these metrics are a great start, it is important to remember that human decision making is not always ideal or feasible. We can instead use some machine learning tools to help us determine the best features to use.\nLet’s perform an exhaustive search over all possible feature combinations to determine the best features to use for our model. We will use the combinations function from the itertools package for this.\n\nfrom itertools import combinations\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\n\n# Define the model\nmodel = RandomForestClassifier(n_estimators = 100, random_state = 0)\n\n# Define the features\nfeatures = X_train.columns\n\n# Define the number of features to select\nn_features = 3\n\n# Perform the search\nbest_score = 0\nbest_features = []\nfor combo in combinations(features, n_features):\n  X_train_subset = X_train[list(combo)]\n  score = cross_val_score(model, X_train_subset, y_train, cv = 5).mean()\n  if score &gt; best_score:\n    best_score = score\n    best_features = combo\n\nprint(\"Best features: \", best_features)\nprint(\"Best score: \", best_score)\n\nBest features:  ('Culmen Length (mm)', 'Culmen Depth (mm)', 'Sex_MALE')\nBest score:  0.9844645550527904\n\n\nWow! That took a long time (over a minute!). It’s important to note that this method will not work for larger datasets, as the number of possible combinations grows exponentially with the number of features. However, for this dataset, it is a feasible method.\nTaking a look at the results, we can see that the best features to use are Culmen Length, Culmen Depth, and Sex. Time to train the model.\n\n\nModel Time\nTo start, lets define our Logistic Regression model. We will use the LogisticRegression class from the scikit-learn library to do this.\n\nfrom sklearn.linear_model import LogisticRegression\n\n# Define the model\nmodel = LogisticRegression(max_iter = 1000)\n\n# Define the features\nfeatures = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\", \"Sex_MALE\", \"Sex_FEMALE\"]\n\n# Train the model\nmodel.fit(X_train[features], y_train)\nprint(\"Train Set Score: \", model.score(X_train[features], y_train))\n\n# Let's now evaluate the model on the test set.\ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\n\nX_test, y_test = prepare_data(test)\nprint(\"Test Set Score: \", model.score(X_test[features], y_test))\n\n\nTrain Set Score:  0.9921875\nTest Set Score:  0.9852941176470589\n\n\nSuccess! Our model has an accuracy of 98% on the test data. This is a great result, but it is important to remember that this is a small dataset, and the model may not perform as well on larger datasets. However, for this dataset, the model is performing very well.\nNext up, let’s visualize the decision boundaries of the model.\n\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom matplotlib.patches import Patch\n\ndef plot_regions(model, X, y):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize = (7, 3))\n\n    # Ensure axarr is a list\n    if not isinstance(axarr, np.ndarray):\n        axarr = np.array([axarr])\n\n    # create a grid\n    grid_x = np.linspace(x0.min(),x0.max(),501)\n    grid_y = np.linspace(x1.min(),x1.max(),501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    for i in range(len(qual_features)):\n      XY = pd.DataFrame({\n          X.columns[0] : XX,\n          X.columns[1] : YY\n      })\n\n      for j in qual_features:\n        XY[j] = 0\n\n      XY[qual_features[i]] = 1\n\n      p = model.predict(XY)\n      p = p.reshape(xx.shape)\n      \n      # use contour plot to visualize the predictions\n      axarr[i].contourf(xx, yy, p, cmap = \"jet\", alpha = 0.2, vmin = 0, vmax = 2)\n      \n      ix = X[qual_features[i]] == 1\n      # plot the data\n      axarr[i].scatter(x0[ix], x1[ix], c = y[ix], cmap = \"jet\", vmin = 0, vmax = 2)\n      \n      axarr[i].set(xlabel = X.columns[0], \n            ylabel  = X.columns[1], \n            title = qual_features[i])\n      \n      patches = []\n      for color, spec in zip([\"red\", \"green\", \"blue\"], [\"Adelie\", \"Chinstrap\", \"Gentoo\"]):\n        patches.append(Patch(color = color, label = spec))\n\n      plt.legend(title = \"Species\", handles = patches, loc = \"best\")\n      \n      plt.tight_layout()\n\nplot_regions(model, X_train[features], y_train)\n\n\n\n\n\n\n\n\n\n# confusion matrix\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\ny_pred = model.predict(X_test[features])\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot = True, fmt = \"d\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.show()\n\n\n\n\n\n\n\n\nThe above confusion matrix indicates that we have pretty great results. We are mostly getting the correct species, with only a few misclassifications. We can see from the graph that the misclassifications are mostly due to special penguin specimens who have outlying features. This is good because it means that our model is likely not overfitting to the training data. Lets verify this using cross-validation.\n\n# cross validation\nfrom sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(model, X_train, y_train, cv = 5)\nscores.mean()\nprint(\"Cross Validation Score: \", scores.mean())\n\nCross Validation Score:  1.0\n\n\n\n\nDiscussion\nIn this post, I explored the differences between the three species of penguins in the Palmer Penguins dataset. I used the dataset to train a machine learning model to classify the species of penguins based on certain measurements. Some of the measurements were quantitative while others were qualitative. I was able to use the combinations function from the itertools package to determine the best features to use for the model. I then trained a logistic regression model from the scikit-learn library on the dataset and visualized the decision boundaries of the model. The model was highly accurate and performed well on the test data. I also used cross-validation to verify that the model was not overfitting to the training data. Overall, the model performed very well on the dataset, and the results were promising."
  },
  {
    "objectID": "posts/palmer penguins/Classifying-Palmer-Penguins.html",
    "href": "posts/palmer penguins/Classifying-Palmer-Penguins.html",
    "title": "Palmer Penguins",
    "section": "",
    "text": "CSCI 0451: Classifying Palmer Penguins\n\nAbstract\nThis post is an exploration of the Palmer Penguins dataset. The dataset contains measurements of penguins from three different species. I will use the dataset to train a machine learning model to classify the species of penguins based on certain measurements. I will primarily be utilizing the pandas library, but I will also make use of the scikit-learn library to train a support vector machine (SVM) model on the dataset and the matplotlib library to visualize the data and the decision boundaries of the model.\n\nimport pandas as pd\n\ntrain_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv\"\ntrain = pd.read_csv(train_url)\ntrain.head()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0809\n31\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN63A1\nYes\n11/24/08\n40.9\n16.6\n187.0\n3200.0\nFEMALE\n9.08458\n-24.54903\nNaN\n\n\n1\nPAL0809\n41\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN74A1\nYes\n11/24/08\n49.0\n19.5\n210.0\n3950.0\nMALE\n9.53262\n-24.66867\nNaN\n\n\n2\nPAL0708\n4\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN32A2\nYes\n11/27/07\n50.0\n15.2\n218.0\n5700.0\nMALE\n8.25540\n-25.40075\nNaN\n\n\n3\nPAL0708\n15\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN38A1\nYes\n12/3/07\n45.8\n14.6\n210.0\n4200.0\nFEMALE\n7.79958\n-25.62618\nNaN\n\n\n4\nPAL0809\n34\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN65A2\nYes\n11/24/08\n51.0\n18.8\n203.0\n4100.0\nMALE\n9.23196\n-24.17282\nNaN\n\n\n\n\n\n\n\nTime to clean the data.\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(train[\"Species\"])\n\ndef prepare_data(df):\n  df = df.drop([\"studyName\", \"Sample Number\", \"Individual ID\", \"Date Egg\", \"Comments\"], axis = 1)\n  df = df[df[\"Sex\"] != \".\"]\n  df = df.dropna()\n  y = le.transform(df[\"Species\"])\n  df = df.drop([\"Species\"], axis = 1)\n  df = pd.get_dummies(df)\n  return df, y\n\nX_train, y_train = prepare_data(train)\n\n\n\n\nData Exploration\nHere are some exploratory visualizations of the data.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Visualization 1\n# Pairplot of the data, colored by species\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nsns.pairplot(train, hue = \"Species\")\nplt.show()\n\n\n\n\n\n\n\n\nThis gives us a great overview of the data at a glance, but let’s take a closer look at some of the features that appear to be the most divisive between species. Seeing as the flipper length does a good job of separating the Gentoo penguins from the other two species, let’s select that at one of our initial features. We also want to look at a metric seems to isolate the two other species. Using the charts on the diagonal, we can see that delta 13 C is good for separating the Chinstraps, and the culmen length is good for separating the Adelies.\n\n# Visualization 2\n# Let's look more at the flipper length, delta 13 c, and culmen length\n# flipper length by species\nsns.boxplot(data = train, x = \"Species\", y = \"Flipper Length (mm)\")\nplt.xticks(rotation = 45)\nplt.title(\"Flipper Length by Species\")\nplt.show()\n# delta 13 c by species\nsns.boxplot(data = train, x = \"Species\", y = \"Delta 13 C (o/oo)\")\nplt.xticks(rotation = 45)\nplt.title(\"Delta 13 C by Species\")\nplt.show()\n# culmen length by species\nsns.boxplot(data = train, x = \"Species\", y = \"Culmen Length (mm)\")\nplt.xticks(rotation = 45)\nplt.title(\"Culmen Length by Species\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNow, its time for some tables. We can use the groupby function to get the mean and median values of the flipper length, delta 13 C, and culmen length for each species. This will give us a good idea of the average values for each species, and will help us to see how the species differ in terms of these features.\n\n# Mean values\nmeans = train.groupby(\"Species\")[[\"Flipper Length (mm)\", \"Delta 13 C (o/oo)\", \"Culmen Length (mm)\"]].mean()\nprint(\"Mean values\")\nprint(means)\n\nMean values\n                                           Flipper Length (mm)  \\\nSpecies                                                          \nAdelie Penguin (Pygoscelis adeliae)                 190.084034   \nChinstrap penguin (Pygoscelis antarctica)           196.000000   \nGentoo penguin (Pygoscelis papua)                   216.752577   \n\n                                           Delta 13 C (o/oo)  \\\nSpecies                                                        \nAdelie Penguin (Pygoscelis adeliae)               -25.796897   \nChinstrap penguin (Pygoscelis antarctica)         -24.553401   \nGentoo penguin (Pygoscelis papua)                 -26.149389   \n\n                                           Culmen Length (mm)  \nSpecies                                                        \nAdelie Penguin (Pygoscelis adeliae)                 38.970588  \nChinstrap penguin (Pygoscelis antarctica)           48.826316  \nGentoo penguin (Pygoscelis papua)                   47.073196  \n\n\n\n# Median values\nmedians = train.groupby(\"Species\")[[\"Flipper Length (mm)\", \"Delta 13 C (o/oo)\", \"Culmen Length (mm)\"]].median()\nprint(\"Median values\")\nprint(medians)\n\nMedian values\n                                           Flipper Length (mm)  \\\nSpecies                                                          \nAdelie Penguin (Pygoscelis adeliae)                      190.0   \nChinstrap penguin (Pygoscelis antarctica)                196.0   \nGentoo penguin (Pygoscelis papua)                        216.0   \n\n                                           Delta 13 C (o/oo)  \\\nSpecies                                                        \nAdelie Penguin (Pygoscelis adeliae)                -25.89709   \nChinstrap penguin (Pygoscelis antarctica)          -24.59467   \nGentoo penguin (Pygoscelis papua)                  -26.20455   \n\n                                           Culmen Length (mm)  \nSpecies                                                        \nAdelie Penguin (Pygoscelis adeliae)                      38.9  \nChinstrap penguin (Pygoscelis antarctica)                49.3  \nGentoo penguin (Pygoscelis papua)                        46.5  \n\n\nWhile these metrics are a great start, it is important to remember that human decision making is not always ideal or feasible. We can instead use some machine learning tools to help us determine the best features to use.\nLet’s perform an exhaustive search over all possible feature combinations to determine the best features to use for our model. We will use the combinations function from the itertools package for this.\n\nfrom itertools import combinations\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\n\n# Define the model\nmodel = RandomForestClassifier(n_estimators = 100, random_state = 0)\n\n# Define the features\nfeatures = X_train.columns\n\n# Define the number of features to select\nn_features = 3\n\n# Perform the search\nbest_score = 0\nbest_features = []\nfor combo in combinations(features, n_features):\n  X_train_subset = X_train[list(combo)]\n  score = cross_val_score(model, X_train_subset, y_train, cv = 5).mean()\n  if score &gt; best_score:\n    best_score = score\n    best_features = combo\n\nprint(\"Best features: \", best_features)\nprint(\"Best score: \", best_score)\n\nBest features:  ('Culmen Length (mm)', 'Culmen Depth (mm)', 'Sex_MALE')\nBest score:  0.9844645550527904\n\n\nWow! That took a long time (over a minute!). It’s important to note that this method will not work for larger datasets, as the number of possible combinations grows exponentially with the number of features. However, for this dataset, it is a feasible method.\nTaking a look at the results, we can see that the best features to use are Culmen Length, Culmen Depth, and Sex. Time to train the model.\n\n\nModel Time\nTo start, lets define our Logistic Regression model. We will use the LogisticRegression class from the scikit-learn library to do this.\n\nfrom sklearn.linear_model import LogisticRegression\n\n# Define the model\nmodel = LogisticRegression(max_iter = 1000)\n\n# Define the features\nfeatures = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\", \"Sex_MALE\", \"Sex_FEMALE\"]\n\n# Train the model\nmodel.fit(X_train[features], y_train)\nprint(\"Train Set Score: \", model.score(X_train[features], y_train))\n\n# Let's now evaluate the model on the test set.\ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\n\nX_test, y_test = prepare_data(test)\nprint(\"Test Set Score: \", model.score(X_test[features], y_test))\n\n\nTrain Set Score:  0.9921875\nTest Set Score:  0.9852941176470589\n\n\nSuccess! Our model has an accuracy of 98% on the test data. This is a great result, but it is important to remember that this is a small dataset, and the model may not perform as well on larger datasets. However, for this dataset, the model is performing very well.\nNext up, let’s visualize the decision boundaries of the model.\n\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom matplotlib.patches import Patch\n\ndef plot_regions(model, X, y):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize = (7, 3))\n\n    # Ensure axarr is a list\n    if not isinstance(axarr, np.ndarray):\n        axarr = np.array([axarr])\n\n    # create a grid\n    grid_x = np.linspace(x0.min(),x0.max(),501)\n    grid_y = np.linspace(x1.min(),x1.max(),501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    for i in range(len(qual_features)):\n      XY = pd.DataFrame({\n          X.columns[0] : XX,\n          X.columns[1] : YY\n      })\n\n      for j in qual_features:\n        XY[j] = 0\n\n      XY[qual_features[i]] = 1\n\n      p = model.predict(XY)\n      p = p.reshape(xx.shape)\n      \n      # use contour plot to visualize the predictions\n      axarr[i].contourf(xx, yy, p, cmap = \"jet\", alpha = 0.2, vmin = 0, vmax = 2)\n      \n      ix = X[qual_features[i]] == 1\n      # plot the data\n      axarr[i].scatter(x0[ix], x1[ix], c = y[ix], cmap = \"jet\", vmin = 0, vmax = 2)\n      \n      axarr[i].set(xlabel = X.columns[0], \n            ylabel  = X.columns[1], \n            title = qual_features[i])\n      \n      patches = []\n      for color, spec in zip([\"red\", \"green\", \"blue\"], [\"Adelie\", \"Chinstrap\", \"Gentoo\"]):\n        patches.append(Patch(color = color, label = spec))\n\n      plt.legend(title = \"Species\", handles = patches, loc = \"best\")\n      \n      plt.tight_layout()\n\nplot_regions(model, X_train[features], y_train)\n\n\n\n\n\n\n\n\n\n# confusion matrix\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\ny_pred = model.predict(X_test[features])\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot = True, fmt = \"d\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.show()\n\n\n\n\n\n\n\n\nThe above confusion matrix indicates that we have pretty great results. We are mostly getting the correct species, with only a few misclassifications. We can see from the graph that the misclassifications are mostly due to special penguin specimens who have outlying features. This is good because it means that our model is likely not overfitting to the training data. Lets verify this using cross-validation.\n\n# cross validation\nfrom sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(model, X_train, y_train, cv = 5)\nscores.mean()\nprint(\"Cross Validation Score: \", scores.mean())\n\nCross Validation Score:  1.0\n\n\n\n\nDiscussion\nIn this post, I explored the differences between the three species of penguins in the Palmer Penguins dataset. I used the dataset to train a machine learning model to classify the species of penguins based on certain measurements. Some of the measurements were quantitative while others were qualitative. I was able to use the combinations function from the itertools package to determine the best features to use for the model. I then trained a logistic regression model from the scikit-learn library on the dataset and visualized the decision boundaries of the model. The model was highly accurate and performed well on the test data. I also used cross-validation to verify that the model was not overfitting to the training data. Overall, the model performed very well on the dataset, and the results were promising."
  }
]